{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c59d053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24545, 16) (5260, 16) (5260, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shipment_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>dispatch_date</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>delay_days</th>\n",
       "      <th>disruption_type</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>source</th>\n",
       "      <th>lead_time_days</th>\n",
       "      <th>delay_severity</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>quarter</th>\n",
       "      <th>year</th>\n",
       "      <th>route_risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O1000</td>\n",
       "      <td>B33</td>\n",
       "      <td>S23</td>\n",
       "      <td>2023-10-27 00:00:00</td>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>resilience</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Minor</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O1001</td>\n",
       "      <td>B1</td>\n",
       "      <td>S20</td>\n",
       "      <td>2023-07-08 00:00:00</td>\n",
       "      <td>2023-07-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>resilience</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Minor</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O1002</td>\n",
       "      <td>B2</td>\n",
       "      <td>S10</td>\n",
       "      <td>2023-12-29 00:00:00</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Shortage</td>\n",
       "      <td>1.0</td>\n",
       "      <td>resilience</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Severe</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O1003</td>\n",
       "      <td>B6</td>\n",
       "      <td>S10</td>\n",
       "      <td>2023-01-17 00:00:00</td>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>resilience</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shipment_id origin destination        dispatch_date delivery_date  \\\n",
       "0       O1000    B33         S23  2023-10-27 00:00:00    2023-10-28   \n",
       "1       O1001     B1         S20  2023-07-08 00:00:00    2023-07-09   \n",
       "2       O1002     B2         S10  2023-12-29 00:00:00    2024-01-07   \n",
       "3       O1003     B6         S10  2023-01-17 00:00:00    2023-01-20   \n",
       "\n",
       "   delay_days disruption_type  risk_score      source  lead_time_days  \\\n",
       "0         0.0             NaN         0.0  resilience             1.0   \n",
       "1         0.0             NaN         0.0  resilience             1.0   \n",
       "2         7.0        Shortage         1.0  resilience             9.0   \n",
       "3         0.0             NaN         0.0  resilience             3.0   \n",
       "\n",
       "  delay_severity  month  weekday  quarter  year  route_risk_score  \n",
       "0          Minor     10        4        4  2023               1.0  \n",
       "1          Minor      7        5        3  2023               1.0  \n",
       "2         Severe     12        4        4  2023               1.0  \n",
       "3       Moderate      1        1        1  2023               1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "#import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "DATA_PROCESSED = \"../data/processed/tabular\"\n",
    "MODELS_DIR = \"../models\"\n",
    "RESULTS_DIR = \"../results/metrics\"\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Files produced by 06_split_data.ipynb\n",
    "TRAIN_PATH = f\"{DATA_PROCESSED}/train.csv\"\n",
    "VAL_PATH   = f\"{DATA_PROCESSED}/val.csv\"\n",
    "TEST_PATH  = f\"{DATA_PROCESSED}/test.csv\"\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_PATH, low_memory=False, parse_dates=True)\n",
    "df_val   = pd.read_csv(VAL_PATH, low_memory=False, parse_dates=True)\n",
    "df_test  = pd.read_csv(TEST_PATH, low_memory=False, parse_dates=True)\n",
    "\n",
    "print(df_train.shape, df_val.shape, df_test.shape)\n",
    "df_train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48a43a",
   "metadata": {},
   "source": [
    "Utility: Feature/Target Auto-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f6b18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification target: disruption_type\n",
      "Regression target: delay_days\n",
      "ID column: shipment_id\n",
      "Date column: dispatch_date\n"
     ]
    }
   ],
   "source": [
    "def find_col(candidates, cols):\n",
    "    \"\"\"Return the first column from candidates that exists in cols; else None.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in cols: \n",
    "            return c\n",
    "    return None\n",
    "\n",
    "cols = [c.lower() for c in df_train.columns]\n",
    "col_map = {c.lower(): c for c in df_train.columns}\n",
    "\n",
    "# Classification target (disruption flag)\n",
    "classification_candidates = [\n",
    "    \"disruption_flag\",\"is_disrupted\",\"disrupted\",\"risk_flag\",\n",
    "    \"has_disruption\",\"disruption\",\"incident_flag\", \"disruption_type\"\n",
    "]\n",
    "clf_target_lc = find_col(classification_candidates, cols)\n",
    "\n",
    "# Regression target (delay days)\n",
    "regression_candidates = [\n",
    "    \"delay_days\",\"delivery_delay_days\",\"delay\",\"days_delayed\",\"delay_in_days\"\n",
    "]\n",
    "reg_target_lc = find_col(regression_candidates, cols)\n",
    "\n",
    "# ID & date columns\n",
    "id_candidates = [\"shipment_id\",\"id\",\"order_id\",\"consignment_id\"]\n",
    "date_candidates = [\"dispatch_date\",\"ship_date\",\"event_time\",\"timestamp\",\"created_at\",\"pickup_date\"]\n",
    "\n",
    "id_col_lc = find_col(id_candidates, cols)\n",
    "date_col_lc = find_col(date_candidates, cols)\n",
    "\n",
    "# Resolve to original column names (case-preserving)\n",
    "clf_target = col_map.get(clf_target_lc) if clf_target_lc else None\n",
    "reg_target = col_map.get(reg_target_lc) if reg_target_lc else None\n",
    "id_col     = col_map.get(id_col_lc) if id_col_lc else None\n",
    "date_col   = col_map.get(date_col_lc) if date_col_lc else None\n",
    "\n",
    "print(\"Classification target:\", clf_target)\n",
    "print(\"Regression target:\", reg_target)\n",
    "print(\"ID column:\", id_col)\n",
    "print(\"Date column:\", date_col)\n",
    "\n",
    "# Guardrails\n",
    "if clf_target is None and reg_target is None:\n",
    "    raise ValueError(\"No target columns detected. Please set clf_target/reg_target manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f47c19",
   "metadata": {},
   "source": [
    "Split Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968379b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " 5,\n",
       " ['risk_score', 'lead_time_days', 'month', 'weekday', 'quarter'],\n",
       " ['origin', 'destination', 'delivery_date', 'source', 'delay_severity'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping obvious non-features\n",
    "drop_cols = set([id_col, date_col, clf_target, reg_target]) - {None}\n",
    "X_train_full = df_train.drop(columns = [c for c in drop_cols if c in df_train.columns])\n",
    "X_val_full   = df_val.drop(columns = [c for c in drop_cols if c in df_val.columns])\n",
    "X_test_full  = df_test.drop(columns = [c for c in drop_cols if c in df_test.columns])\n",
    "\n",
    "#Targets\n",
    "y_train_clf = df_train[clf_target] if clf_target in df_train.columns else None\n",
    "y_val_clf   = df_val[clf_target]   if clf_target in df_val.columns else None\n",
    "y_test_clf  = df_test[clf_target]  if clf_target in df_test.columns else None\n",
    "\n",
    "y_train_reg = df_train[reg_target] if reg_target in df_train.columns else None\n",
    "y_val_reg   = df_val[reg_target]   if reg_target in df_val.columns else None\n",
    "y_test_reg  = df_test[reg_target]  if reg_target in df_test.columns else None\n",
    "\n",
    "num_cols = [c for c in X_train_full.columns if pd.api.types.is_numeric_dtype(X_train_full[c])]\n",
    "cat_cols = [c for c in X_train_full.columns if c not in num_cols]\n",
    "\n",
    "len(num_cols), len(cat_cols), num_cols[:5], cat_cols[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb9b58",
   "metadata": {},
   "source": [
    "Common Preprocess Pipline (Impute + Scale + One-Hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbdb2892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessor ready.\n",
      "Numeric: ['delay_days', 'risk_score', 'lead_time_days', 'month', 'weekday', 'quarter', 'year']\n",
      "Special Numeric: ['route_risk_score']\n",
      "Special Cat: ['disruption_type']\n",
      "Flags: []\n",
      "General Cat: ['shipment_id', 'origin', 'destination', 'dispatch_date', 'delivery_date', 'source', 'delay_severity']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ---------------------------\n",
    "# Identify column groups\n",
    "# ---------------------------\n",
    "\n",
    "# Special categorical\n",
    "special_cat_cols = [\"disruption_type\"] if \"disruption_type\" in df_train.columns else []\n",
    "\n",
    "# Binary/flag columns\n",
    "flag_cols = [c for c in df_train.columns \n",
    "             if c.lower() in [\"risk_flag\",\"disruption_flag\",\"incident_flag\"]]\n",
    "\n",
    "# Special numeric\n",
    "special_num_cols = [c for c in df_train.columns \n",
    "                    if c.lower() in [\"route_risk_score\", \"lead_time_delays\"]]\n",
    "\n",
    "# General numeric (excluding special numeric)\n",
    "num_cols = [c for c in df_train.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "            if c not in special_num_cols and c not in flag_cols]\n",
    "\n",
    "# General categorical (excluding special cat + flags)\n",
    "cat_cols = [c for c in df_train.select_dtypes(include=\"object\").columns\n",
    "            if c not in special_cat_cols and c not in flag_cols]\n",
    "\n",
    "# ---------------------------\n",
    "# Pipelines\n",
    "# ---------------------------\n",
    "\n",
    "# General numeric\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "# Special numeric (route_risk_score, lead_time_delays) → fill with 0\n",
    "special_num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "    (\"scaler\", StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "# Special categorical: disruption_type\n",
    "special_cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"none\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "])\n",
    "\n",
    "# Flags → impute with 0 (no risk/disruption/incident)\n",
    "flag_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0))\n",
    "    # no encoding needed, already binary\n",
    "])\n",
    "\n",
    "# General categorical\n",
    "general_cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# Final ColumnTransformer\n",
    "# ---------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipeline, num_cols),\n",
    "        (\"special_num\", special_num_pipeline, special_num_cols),\n",
    "        (\"special_cat\", special_cat_pipeline, special_cat_cols),\n",
    "        (\"flags\", flag_pipeline, flag_cols),\n",
    "        (\"general_cat\", general_cat_pipeline, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "print(\"✅ Preprocessor ready.\")\n",
    "print(\"Numeric:\", num_cols)\n",
    "print(\"Special Numeric:\", special_num_cols)\n",
    "print(\"Special Cat:\", special_cat_cols)\n",
    "print(\"Flags:\", flag_cols)\n",
    "print(\"General Cat:\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfeca3",
   "metadata": {},
   "source": [
    "Classification: Risk Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
    "                             classification_report, confusion_matrix)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_results = {}\n",
    "\n",
    "if clf_target is not None:\n",
    "    # Ensure binary target as 0/1 if it is categorical/textual\n",
    "    def to_binary(y):\n",
    "        # treat ['none','no','false','0'] as 0; anything else as 1\n",
    "        if y.dtype == object:\n",
    "            y = y.fillna(\"none\").str.lower().map(lambda v: 0 if v in ['none', 'no', 'false', '0', 'nan', 'unknown'] else 1)\n",
    "            return y.astype(int)\n",
    "        return y.astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
